{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - What are the prerequisites for this course?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "    \n",
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)\n",
    "\n",
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59aacb94bc2f422fb9b6440c0eee1de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185c6395c64c4e8eb2ddef6f5ff22cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9bec4dd36b4719870dd37219078f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d704a18fd1547718723a925f398b4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab31fe9159a146eab9b1c7fac8f288ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e59627bc8b4eec98896478070240be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aee123ae0fd462d85fe4825732b44aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ec2892e1404d5095842291fcfdc88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11fb6e218844062972af4e559f718bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c4a23b6f0d4a4e92d1fdd6141c28d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586f19a15c5a4d008c2e7c46082cbc6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentence = model.encode('This is awesome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations = []\n",
    "for doc in documents:\n",
    "    doc['text_vector'] = model.encode(doc['text']).tolist()\n",
    "    operations.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'a60340d192b9', 'cluster_name': 'docker-cluster', 'cluster_uuid': '8xG7he17RnCD4eieXjpeGQ', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} ,\n",
    "            \"text_vector\": {\"type\": \"dense_vector\", \"dims\": 768, \"index\": True, \"similarity\": \"cosine\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in operations:\n",
    "    try:\n",
    "        es_client.index(index= index_name, document= doc)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"Mac or windows\"\n",
    "vector_search_term = model.encode(search_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"field\": \"text_vector\",\n",
    "    \"query_vector\": vector_search_term,\n",
    "    \"k\": 5,\n",
    "    \"num_candidates\": 10000, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = es_client.search(index=index_name, knn=query, source=[\"text\", \"section\", \"question\", \"course\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'course-questions',\n",
       "  '_id': '23AMlJABGiD4lVs_kclN',\n",
       "  '_score': 0.739895,\n",
       "  '_source': {'question': 'Environment - Is the course [Windows/mac/Linux/...] friendly?',\n",
       "   'course': 'data-engineering-zoomcamp',\n",
       "   'section': 'General course-related questions',\n",
       "   'text': 'Yes! Linux is ideal but technically it should not matter. Students last year used all 3 OSes successfully'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': '7nAMlJABGiD4lVs_mczA',\n",
       "  '_score': 0.61556023,\n",
       "  '_source': {'question': 'WSL instructions',\n",
       "   'course': 'mlops-zoomcamp',\n",
       "   'section': 'Module 1: Introduction',\n",
       "   'text': 'If you wish to use WSL on your windows machine, here are the setup instructions:\\nCommand: Sudo apt install wget\\nGet Anaconda download address here. wget <download address>\\nTurn on Docker Desktop WFree Download | AnacondaSL2\\nCommand: git clone <github repository address>\\nVSCODE on WSL\\nJupyter: pip3 install jupyter\\nAdded by Gregory Morris (gwm1980@gmail.com)\\nAll in all softwares at one shop:\\nYou can use anaconda which has all built in services like pycharm, jupyter\\nAdded by Khaja Zaffer (khajazaffer@aln.iseg.ulisboa.pt)\\nFor windows “wsl --install” in Powershell\\nAdded by Vadim Surin (vdmsurin@gmai.com)'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'CHAMlJABGiD4lVs_l8xs',\n",
       "  '_score': 0.6108302,\n",
       "  '_source': {'question': 'How to install WSL on Windows 10 and 11 ?',\n",
       "   'course': 'machine-learning-zoomcamp',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'text': 'It is quite simple, and you can follow these instructions here:\\nhttps://www.youtube.com/watch?v=qYlgUDKKK5A&ab_channel=NeuralNine\\nMake sure that you have “Virtual Machine Platform” feature activated in your Windows “Features”. To do that, search “features” in the research bar and see if the checkbox is selected. You also need to make sure that your system (in the bios) is able to virtualize. This is usually the case.\\nIn the Microsoft Store: look for ‘Ubuntu’ or ‘Debian’ (or any linux distribution you want) and install it\\nOnce it is downloaded, open the app and choose a username and a password (secured one). When you type your password, nothing will show in the window, which is normal: the writing is invisible.\\nYou are now inside of your linux system. You can test some commands such as “pwd”. You are not in your Windows system.\\nTo go to your windows system: you need to go back two times with cd ../.. And then go to the “mnt” directory with cd mnt. If you list here your files, you will see your disks. You can move to the desired folder, for example here I moved to the ML_Zoomcamp folder:\\nPython should be already installed but you can check it by running sudo apt install python3 command.\\nYou can make your actual folder your default folder when you open your Ubuntu terminal with this command : echo \"cd ../../mnt/your/folder/path\" >> ~/.bashrc\\nYou can disable bell sounds (when you type something that does not exist for example) by modifying the inputrc file with this command: sudo vim /etc/inputrc\\nYou have to uncomment the set bell-style none line -> to do that, press the “i” keyboard letter (for insert) and go with your keyboard to this line. Delete the # and then press the Escape keyboard touch and finally press “:wq” to write (it saves your modifications) then quit.\\nYou can check that your modifications are taken into account by opening a new terminal (you can pin it to your task bar so you do not have to go to the Microsoft app each time).\\nYou will need to install pip by running this command sudo apt install python3-pip\\nNB: I had this error message when trying to install pipenv (https://github.com/microsoft/WSL/issues/5663):\\n/sbin/ldconfig.real: Can\\'t link /usr/lib/wsl/lib/libnvoptix_loader.so.1 to libnvoptix.so.1\\n/sbin/ldconfig.real: /usr/lib/wsl/lib/libcuda.so.1 is not a symbolic link\\nSo I had to create the following symbolic link:\\nsudo ln -s /usr/lib/wsl/lib/libcuda.so.1 /usr/lib64/libcuda.so\\n(Mélanie Fouesnard)'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'P3AMlJABGiD4lVs_l8z7',\n",
       "  '_score': 0.610363,\n",
       "  '_source': {'question': 'What is the difference between bagging and boosting?',\n",
       "   'course': 'machine-learning-zoomcamp',\n",
       "   'section': '6. Decision Trees and Ensemble Learning',\n",
       "   'text': 'For ensemble algorithms, during the week 6, one bagging algorithm and one boosting algorithm were presented: Random Forest and XGBoost, respectively.\\nRandom Forest trains several models in parallel. The output can be, for example, the average value of all the outputs of each model. This is called bagging.\\nXGBoost trains several models sequentially: the previous model error is used to train the following model. Weights are used to ponderate the models such as the best models have higher weights and are therefore favored for the final output. This method is called boosting.\\nNote that boosting is not necessarily better than bagging.\\nMélanie Fouesnard\\nBagging stands for “Bootstrap Aggregation” - it involves taking multiple samples with replacement to derive multiple training datasets from the original training dataset (bootstrapping), training a classifier (e.g. decision trees or stumps for Random Forests) on each such training dataset, and then combining the the predictions (aggregation) to obtain the final prediction. For classification, predictions are combined via voting; for regression, via averaging. Bagging can be done in parallel, since the various classifiers are independent. Bagging decreases variance (but not bias) and is robust against overfitting.\\nBoosting, on the other hand, is sequential - each model learns from the mistakes of its predecessor. Observations are given different weights - observations/samples misclassified by the previous classifier are given a higher weight, and this process is continued until a stopping condition is reached (e.g. max. No. of models is reached, or error is acceptably small, etc.). Boosting reduces bias & is generally more accurate than bagging, but can be prone to overfitting.\\nRileen'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'dnAMlJABGiD4lVs_lcvl',\n",
       "  '_score': 0.60348487,\n",
       "  '_source': {'question': \"Any particular hardware requirements for the course or everything is mostly cloud? TIA! Couldn't really find this in the FAQ.\",\n",
       "   'course': 'machine-learning-zoomcamp',\n",
       "   'section': 'General course-related questions',\n",
       "   'text': 'For the Machine Learning part, all you need is a working laptop with an internet connection. The Deep Learning part is more resource intensive, but for that you can use a cloud (we use Saturn cloud but can be anything else).\\n(Rileen Sinha; based on response by Alexey on Slack)'}}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes! Linux is ideal but technically it should not matter. Students last year used all 3 OSes successfully\n",
      "\n",
      "If you wish to use WSL on your windows machine, here are the setup instructions:\n",
      "Command: Sudo apt install wget\n",
      "Get Anaconda download address here. wget <download address>\n",
      "Turn on Docker Desktop WFree Download | AnacondaSL2\n",
      "Command: git clone <github repository address>\n",
      "VSCODE on WSL\n",
      "Jupyter: pip3 install jupyter\n",
      "Added by Gregory Morris (gwm1980@gmail.com)\n",
      "All in all softwares at one shop:\n",
      "You can use anaconda which has all built in services like pycharm, jupyter\n",
      "Added by Khaja Zaffer (khajazaffer@aln.iseg.ulisboa.pt)\n",
      "For windows “wsl --install” in Powershell\n",
      "Added by Vadim Surin (vdmsurin@gmai.com)\n",
      "\n",
      "It is quite simple, and you can follow these instructions here:\n",
      "https://www.youtube.com/watch?v=qYlgUDKKK5A&ab_channel=NeuralNine\n",
      "Make sure that you have “Virtual Machine Platform” feature activated in your Windows “Features”. To do that, search “features” in the research bar and see if the checkbox is selected. You also need to make sure that your system (in the bios) is able to virtualize. This is usually the case.\n",
      "In the Microsoft Store: look for ‘Ubuntu’ or ‘Debian’ (or any linux distribution you want) and install it\n",
      "Once it is downloaded, open the app and choose a username and a password (secured one). When you type your password, nothing will show in the window, which is normal: the writing is invisible.\n",
      "You are now inside of your linux system. You can test some commands such as “pwd”. You are not in your Windows system.\n",
      "To go to your windows system: you need to go back two times with cd ../.. And then go to the “mnt” directory with cd mnt. If you list here your files, you will see your disks. You can move to the desired folder, for example here I moved to the ML_Zoomcamp folder:\n",
      "Python should be already installed but you can check it by running sudo apt install python3 command.\n",
      "You can make your actual folder your default folder when you open your Ubuntu terminal with this command : echo \"cd ../../mnt/your/folder/path\" >> ~/.bashrc\n",
      "You can disable bell sounds (when you type something that does not exist for example) by modifying the inputrc file with this command: sudo vim /etc/inputrc\n",
      "You have to uncomment the set bell-style none line -> to do that, press the “i” keyboard letter (for insert) and go with your keyboard to this line. Delete the # and then press the Escape keyboard touch and finally press “:wq” to write (it saves your modifications) then quit.\n",
      "You can check that your modifications are taken into account by opening a new terminal (you can pin it to your task bar so you do not have to go to the Microsoft app each time).\n",
      "You will need to install pip by running this command sudo apt install python3-pip\n",
      "NB: I had this error message when trying to install pipenv (https://github.com/microsoft/WSL/issues/5663):\n",
      "/sbin/ldconfig.real: Can't link /usr/lib/wsl/lib/libnvoptix_loader.so.1 to libnvoptix.so.1\n",
      "/sbin/ldconfig.real: /usr/lib/wsl/lib/libcuda.so.1 is not a symbolic link\n",
      "So I had to create the following symbolic link:\n",
      "sudo ln -s /usr/lib/wsl/lib/libcuda.so.1 /usr/lib64/libcuda.so\n",
      "(Mélanie Fouesnard)\n",
      "\n",
      "For ensemble algorithms, during the week 6, one bagging algorithm and one boosting algorithm were presented: Random Forest and XGBoost, respectively.\n",
      "Random Forest trains several models in parallel. The output can be, for example, the average value of all the outputs of each model. This is called bagging.\n",
      "XGBoost trains several models sequentially: the previous model error is used to train the following model. Weights are used to ponderate the models such as the best models have higher weights and are therefore favored for the final output. This method is called boosting.\n",
      "Note that boosting is not necessarily better than bagging.\n",
      "Mélanie Fouesnard\n",
      "Bagging stands for “Bootstrap Aggregation” - it involves taking multiple samples with replacement to derive multiple training datasets from the original training dataset (bootstrapping), training a classifier (e.g. decision trees or stumps for Random Forests) on each such training dataset, and then combining the the predictions (aggregation) to obtain the final prediction. For classification, predictions are combined via voting; for regression, via averaging. Bagging can be done in parallel, since the various classifiers are independent. Bagging decreases variance (but not bias) and is robust against overfitting.\n",
      "Boosting, on the other hand, is sequential - each model learns from the mistakes of its predecessor. Observations are given different weights - observations/samples misclassified by the previous classifier are given a higher weight, and this process is continued until a stopping condition is reached (e.g. max. No. of models is reached, or error is acceptably small, etc.). Boosting reduces bias & is generally more accurate than bagging, but can be prone to overfitting.\n",
      "Rileen\n",
      "\n",
      "For the Machine Learning part, all you need is a working laptop with an internet connection. The Deep Learning part is more resource intensive, but for that you can use a cloud (we use Saturn cloud but can be anything else).\n",
      "(Rileen Sinha; based on response by Alexey on Slack)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ans in res[\"hits\"][\"hits\"]:\n",
    "    print(ans['_source']['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
