{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8247dc5-2534-4e24-8a7f-13d3185c1ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-20 19:11:13--  https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-06-20 19:11:13 (9.18 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd361119-ea75-427e-a4c9-5b74ed25f58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-27 16:23:43--  https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 658332 (643K) [text/plain]\n",
      "Saving to: ‘documents.json’\n",
      "\n",
      "documents.json      100%[===================>] 642.90K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2024-06-27 16:23:43 (17.9 MB/s) - ‘documents.json’ saved [658332/658332]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11f636ca-af01-4348-a263-e18b94c96380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '853b7f686046', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'Mk1wWHTMRgmGbAUhXVIfEQ', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "#start elastic search from docker image first\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647964bc-8c76-4e78-85f5-ca8fcccdfa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797441bd-5eab-41c1-8629-29491d9ac5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environ{'XDG_SESSION_ID': '2',\n",
       "        'TERM_PROGRAM': 'vscode',\n",
       "        'HOSTNAME': 'ip-172-31-0-159.dev-sunrun.local',\n",
       "        'SSL_CERT_FILE': '/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem',\n",
       "        'TERM': 'xterm-color',\n",
       "        'SHELL': '/bin/bash',\n",
       "        'HISTSIZE': '1000',\n",
       "        'SSH_CLIENT': '172.31.0.217 55346 22',\n",
       "        'TERM_PROGRAM_VERSION': '1.89.1',\n",
       "        'USER': 'ec2-user',\n",
       "        'LS_COLORS': 'rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:',\n",
       "        'LD_LIBRARY_PATH': '/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/opt/aws-ofi-nccl/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/opt/aws-ofi-nccl/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/opt/aws-ofi-nccl/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib',\n",
       "        'PATH': '/opt/amazon/openmpi/bin/:/opt/amazon/efa/bin/:/opt/conda/bin:/usr/local/cuda/bin:/usr/local/cuda/include:/usr/libexec/gcc/x86_64-redhat-linux/7:/opt/aws/bin:/home/ec2-user/.vscode-server/cli/servers/Stable-dc96b837cf6bb4af9cd736aa3af08cf8279f7685/server/bin/remote-cli:/opt/amazon/openmpi/bin/:/opt/amazon/efa/bin/:/opt/conda/bin:/usr/local/cuda/bin:/usr/local/cuda/include:/usr/libexec/gcc/x86_64-redhat-linux/7:/opt/aws/bin:/opt/amazon/openmpi/bin/:/opt/amazon/efa/bin/:/opt/conda/bin:/usr/local/cuda/bin:/usr/local/cuda/include:/usr/libexec/gcc/x86_64-redhat-linux/7:/opt/aws/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/ec2-user/.local/bin:/home/ec2-user/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin',\n",
       "        'MAIL': '/var/spool/mail/ec2-user',\n",
       "        'PWD': '/home/ec2-user',\n",
       "        'LANG': 'en_US.UTF-8',\n",
       "        'MODULEPATH': '/opt/amazon/modules/modulefiles:/opt/amazon/modules/modulefiles:/opt/amazon/modules/modulefiles:/usr/share/Modules/modulefiles:/etc/modulefiles',\n",
       "        'LOADEDMODULES': '',\n",
       "        'VSCODE_GIT_ASKPASS_EXTRA_ARGS': '',\n",
       "        'HISTCONTROL': 'ignoredups',\n",
       "        'SSL_CERT_DIR': '/etc/pki/tls/certs',\n",
       "        'HOME': '/home/ec2-user',\n",
       "        'SHLVL': '5',\n",
       "        'VSCODE_GIT_ASKPASS_MAIN': '/home/ec2-user/.vscode-server/cli/servers/Stable-dc96b837cf6bb4af9cd736aa3af08cf8279f7685/server/extensions/git/dist/askpass-main.js',\n",
       "        'LOGNAME': 'ec2-user',\n",
       "        'VSCODE_GIT_IPC_HANDLE': '/run/user/1000/vscode-git-daac1b0e52.sock',\n",
       "        'SSH_CONNECTION': '172.31.0.217 55346 172.31.0.159 22',\n",
       "        'VSCODE_IPC_HOOK_CLI': '/run/user/1000/vscode-ipc-4fb0ec1c-b822-41b4-b709-5388e7c56ece.sock',\n",
       "        'MODULESHOME': '/usr/share/Modules',\n",
       "        'LESSOPEN': '||/usr/bin/lesspipe.sh %s',\n",
       "        'BROWSER': '/home/ec2-user/.vscode-server/cli/servers/Stable-dc96b837cf6bb4af9cd736aa3af08cf8279f7685/server/bin/helpers/browser.sh',\n",
       "        'VSCODE_GIT_ASKPASS_NODE': '/home/ec2-user/.vscode-server/cli/servers/Stable-dc96b837cf6bb4af9cd736aa3af08cf8279f7685/server/node',\n",
       "        'GIT_ASKPASS': '/home/ec2-user/.vscode-server/cli/servers/Stable-dc96b837cf6bb4af9cd736aa3af08cf8279f7685/server/extensions/git/dist/askpass.sh',\n",
       "        'XDG_RUNTIME_DIR': '/run/user/1000',\n",
       "        'COLORTERM': 'truecolor',\n",
       "        'BASH_FUNC_module()': '() {  eval `/usr/bin/modulecmd bash $*`\\n}',\n",
       "        '_': '/opt/conda/bin/jupyter',\n",
       "        'JPY_SESSION_NAME': '/home/ec2-user/LLMs-RAG/02-open-source-llm/ministral7Bmodel.ipynb',\n",
       "        'JPY_PARENT_PID': '5934',\n",
       "        'PYDEVD_USE_FRAME_EVAL': 'NO',\n",
       "        'CLICOLOR': '1',\n",
       "        'FORCE_COLOR': '1',\n",
       "        'CLICOLOR_FORCE': '1',\n",
       "        'PAGER': 'cat',\n",
       "        'GIT_PAGER': 'cat',\n",
       "        'MPLBACKEND': 'module://matplotlib_inline.backend_inline',\n",
       "        'KMP_DUPLICATE_LIB_OK': 'True',\n",
       "        'KMP_INIT_AT_FORK': 'FALSE',\n",
       "        'HG_TOKE': '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'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef776b73-fc94-4157-b9a7-be7d940c9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0499dd39-e4a1-4494-a50b-19e8fe0dac0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe5d8c9c4544416b0e90cb6d8b880a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login(token= os.environ.get('HG_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f454135f-80b4-46c2-beb6-a8a094b985ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c27de85fa748849b6e1338d56e3547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9158b23fd14246bac0eb9db2a2948c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc54fc570914a90bb283673776fc3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd52cfb42db745a9bc979579428a9b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdfcc4d1a134f04b25648d883303c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e891ea86db4ee4a9ee52e2427a051c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5f1536ab2c441f9c0f39cc37273007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\", device_map=\"auto\", load_in_4bit=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3443e151-f05b-4aa3-bbe9-d8955ae7d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", padding_side=\"left\")\n",
    "model_inputs = tokenizer([\"Hi what a beatifull day here in Denver area\"], return_tensors=\"pt\").to(\"cuda\")\n",
    "generated_ids = model.generate(**model_inputs)\n",
    "tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29973f7f-9f57-4897-93c3-dbda18d5ca3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi what a beatifull day here in Denver area. I am a new member and I'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b69ef1ef-9dac-4156-a4cf-38b456467d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'r') as f:\n",
    "    doc_raws = json.load(f)\n",
    "documents = []\n",
    "for course_dict in doc_raws:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6d6cd2a-06d0-401e-8fb1-e521699080ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c7ef06196b4aef9006c0f9169c328f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "index_name = \"module_02_index\"\n",
    "#es_client.indices.create(index = index_name, body = index_settings)\n",
    "from tqdm.auto import tqdm\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index = index_name, document = doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88afb710-0be6-4261-9f0d-5760e6a7e0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f5740d7a290>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = minsearch.Index(text_fields = ['question', 'text', 'section'],\n",
    "                         keyword_fields = ['course']\n",
    "                        )\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "992b345f-e6c1-43cd-9366-9f84c6bb4d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "    result  = index.search(query = query,\n",
    "                 boost_dict = boost,\n",
    "                 num_results = 5\n",
    "                )\n",
    "    return result\n",
    "\n",
    "def elastic_search (query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es_result = es_client.search(index = index_name, body=search_query)\n",
    "    es_result_docs = []\n",
    "    for hit in es_result['hits']['hits']:\n",
    "        es_result_docs.append(hit['_source'])\n",
    "\n",
    "\n",
    "    return es_result_docs\n",
    "    \n",
    "def build_prompt(query, search_result):\n",
    "    \n",
    "\n",
    "    context = \"\"\n",
    "    for doc in search_result:\n",
    "        context =context + f\"section :{doc['section']} \\nquestion:{doc['question']}\\nanswer:{doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "    You are a course teaching assistant. Answer the given QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    \n",
    "    QUESTION: {question}\\n\n",
    "    CONTEXT: {context}\n",
    "    \"\"\".strip()\n",
    "    prompt = prompt_template.format(question = query, \n",
    "                                    context = context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm (prompt):\n",
    "    model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "    generated_ids = model.generate(**model_inputs, max_length = 1000)\n",
    "    result = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0df430f-eb3b-4ade-ac58-34e0e2a2c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    results = elastic_search(query)#search(query)\n",
    "    prompt = build_prompt(query, results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "869badb2-cc2c-4c36-8cb9-8a99befaddc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You are a course teaching assistant. Answer the given QUESTION based on the CONTEXT from the FAQ database.\\n    Use only the facts from the CONTEXT when answering the QUESTION.\\n    \\n    QUESTION: When will module 3 on llm and rag will start?\\n\\n    CONTEXT: section :General course-related questions \\nquestion:Course - When will the course start?\\nanswer:The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours\\'\\' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club\\'s Slack and join the channel.\\n\\nsection :General course-related questions \\nquestion:Course - When will the course start?\\nanswer:The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours\\'\\' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club\\'s Slack and join the channel.\\n\\nsection :General course-related questions \\nquestion:Office Hours - I can’t attend the “Office hours” / workshop, will it be recorded?\\nanswer:Yes! Every “Office Hours” will be recorded and available a few minutes after the live session is over; so you can view (or rewatch) whenever you want.\\n\\nsection :General course-related questions \\nquestion:Office Hours - I can’t attend the “Office hours” / workshop, will it be recorded?\\nanswer:Yes! Every “Office Hours” will be recorded and available a few minutes after the live session is over; so you can view (or rewatch) whenever you want.\\n\\nsection :Module 5: pyspark \\nquestion:Spark fails when reading from BigQuery and using `.show()` on `SELECT` queries\\nanswer:✅I got it working using `gcs-connector-hadoop-2.2.5-shaded.jar` and Spark 3.1\\nI also added the google_credentials.json and .p12 to auth with gcs. These files are downloadable from GCP Service account.\\nTo create the SparkSession:\\nspark = SparkSession.builder.master(\\'local[*]\\') \\\\\\n.appName(\\'spark-read-from-bigquery\\') \\\\\\n.config(\\'BigQueryProjectId\\',\\'razor-project-xxxxxxx) \\\\\\n.config(\\'BigQueryDatasetLocation\\',\\'de_final_data\\') \\\\\\n.config(\\'parentProject\\',\\'razor-project-xxxxxxx) \\\\\\n.config(\"google.cloud.auth.service.account.enable\", \"true\") \\\\\\n.config(\"credentialsFile\", \"google_credentials.json\") \\\\\\n.config(\"GcpJsonKeyFile\", \"google_credentials.json\") \\\\\\n.config(\"spark.driver.memory\", \"4g\") \\\\\\n.config(\"spark.executor.memory\", \"2g\") \\\\\\n.config(\"spark.memory.offHeap.enabled\",True) \\\\\\n.config(\"spark.memory.offHeap.size\",\"5g\") \\\\\\n.config(\\'google.cloud.auth.service.account.json.keyfile\\', \"google_credentials.json\") \\\\\\n.config(\"fs.gs.project.id\", \"razor-project-xxxxxxx\") \\\\\\n.config(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\\\\n.config(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\") \\\\\\n.getOrCreate()\\n\\nsection :Module 5: pyspark \\nquestion:Spark fails when reading from BigQuery and using `.show()` on `SELECT` queries\\nanswer:✅I got it working using'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"When will module 3 on llm and rag will start?\"\n",
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19c199d8-c63c-4bf4-863b-81defe22950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d41d2d4-00c3-4f39-a7d9-ea6cd63ecaea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
