{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8247dc5-2534-4e24-8a7f-13d3185c1ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-20 19:11:13--  https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-06-20 19:11:13 (9.18 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd361119-ea75-427e-a4c9-5b74ed25f58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-27 16:23:43--  https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 658332 (643K) [text/plain]\n",
      "Saving to: ‘documents.json’\n",
      "\n",
      "documents.json      100%[===================>] 642.90K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2024-06-27 16:23:43 (17.9 MB/s) - ‘documents.json’ saved [658332/658332]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11f636ca-af01-4348-a263-e18b94c96380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'a76e50f4ab61', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'C591eCJ_T-yJBqFGpZx1kg', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "from elasticsearch import Elasticsearch\n",
    "#start elastic search from docker image first\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef776b73-fc94-4157-b9a7-be7d940c9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b69ef1ef-9dac-4156-a4cf-38b456467d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'r') as f:\n",
    "    doc_raws = json.load(f)\n",
    "documents = []\n",
    "for course_dict in doc_raws:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6d6cd2a-06d0-401e-8fb1-e521699080ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59f9bb597424ba9b0ec85ed6cfef7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "index_name = \"module_02_index\"\n",
    "es_client.indices.create(index = index_name, body = index_settings)\n",
    "from tqdm.auto import tqdm\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index = index_name, document = doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a5e51ff-d80d-4bb8-a133-44848632cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88afb710-0be6-4261-9f0d-5760e6a7e0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f5b7ae70880>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = minsearch.Index(text_fields = ['question', 'text', 'section'],\n",
    "                         keyword_fields = ['course']\n",
    "                        )\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "992b345f-e6c1-43cd-9366-9f84c6bb4d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "    result  = index.search(query = query,\n",
    "                 boost_dict = boost,\n",
    "                 num_results = 5\n",
    "                )\n",
    "    return result\n",
    "\n",
    "def elastic_search (query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es_result = es_client.search(index = index_name, body=search_query)\n",
    "    es_result_docs = []\n",
    "    for hit in es_result['hits']['hits']:\n",
    "        es_result_docs.append(hit['_source'])\n",
    "\n",
    "\n",
    "    return es_result_docs\n",
    "    \n",
    "def build_prompt(query, search_result):\n",
    "\n",
    "    context = \"\"\n",
    "    for doc in search_result:\n",
    "        context =context + f\"section :{doc['section']} \\nquestion:{doc['question']}\\nanswer:{doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "    You are a course teaching assistant. Answer the given QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    \n",
    "    QUESTION: {question}\\n\n",
    "    CONTEXT: {context}\n",
    "    \"\"\".strip()\n",
    "    prompt = prompt_template.format(question = query, \n",
    "                                    context = context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm (prompt, generate_params =None):\n",
    "    if generate_params is None:\n",
    "        generate_params= {}\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids #.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids,\n",
    "                             max_length = generate_params.get('max_length', 100),\n",
    "                             num_beams = generate_params.get('num_beams',5),\n",
    "                             do_sample=generate_params.get(\"do_sample\", False),\n",
    "                            temperature=generate_params.get(\"temperature\", 1.0),\n",
    "                            top_k=generate_params.get(\"top_k\", 50),\n",
    "                            top_p=generate_params.get(\"top_p\", 0.95)\n",
    "                            )\n",
    "    result = tokenizer.decode(outputs[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0df430f-eb3b-4ade-ac58-34e0e2a2c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    results = elastic_search(query)#search(query)\n",
    "    prompt = build_prompt(query, results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "869badb2-cc2c-4c36-8cb9-8a99befaddc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes. You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.</s>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"The course on llms and rag is awesome, I love it\"\n",
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c199d8-c63c-4bf4-863b-81defe22950b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
